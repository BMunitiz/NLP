{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef2616f-20f4-4e21-9682-885fe9bdea9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (7.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (3.20.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: keras_nlp in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (0.17.0)\n",
      "Requirement already satisfied: keras-hub==0.17.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras_nlp) (0.17.0)\n",
      "Requirement already satisfied: absl-py in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras-hub==0.17.0->keras_nlp) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras-hub==0.17.0->keras_nlp) (2.0.2)\n",
      "Requirement already satisfied: packaging in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras-hub==0.17.0->keras_nlp) (24.1)\n",
      "Requirement already satisfied: regex in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras-hub==0.17.0->keras_nlp) (2024.11.6)\n",
      "Requirement already satisfied: rich in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras-hub==0.17.0->keras_nlp) (13.9.4)\n",
      "Requirement already satisfied: kagglehub in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras-hub==0.17.0->keras_nlp) (0.3.4)\n",
      "Requirement already satisfied: requests in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from kagglehub->keras-hub==0.17.0->keras_nlp) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from kagglehub->keras-hub==0.17.0->keras_nlp) (4.67.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from rich->keras-hub==0.17.0->keras_nlp) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from rich->keras-hub==0.17.0->keras_nlp) (2.15.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from rich->keras-hub==0.17.0->keras_nlp) (4.11.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.17.0->keras_nlp) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests->kagglehub->keras-hub==0.17.0->keras_nlp) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests->kagglehub->keras-hub==0.17.0->keras_nlp) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests->kagglehub->keras-hub==0.17.0->keras_nlp) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests->kagglehub->keras-hub==0.17.0->keras_nlp) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install  tensorflow\n",
    "!pip install keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6089107-866c-4057-aa5c-d0e1c716ce86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (4.9.3)\n",
      "Requirement already satisfied: absl-py in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: array-record in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (0.4.1)\n",
      "Requirement already satisfied: click in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (0.1.8)\n",
      "Requirement already satisfied: etils>=0.9.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (1.5.2)\n",
      "Requirement already satisfied: numpy in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (2.0.2)\n",
      "Requirement already satisfied: promise in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (2.32.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (1.16.1)\n",
      "Requirement already satisfied: termcolor in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (2.5.0)\n",
      "Requirement already satisfied: toml in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (4.67.0)\n",
      "Requirement already satisfied: wrapt in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: fsspec in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (2024.10.0)\n",
      "Requirement already satisfied: importlib_resources in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (6.4.5)\n",
      "Requirement already satisfied: typing_extensions in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.11.0)\n",
      "Requirement already satisfied: zipp in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.20.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2024.8.30)\n",
      "Requirement already satisfied: six in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from promise->tensorflow_datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fafafc30-df92-4602-b8a8-85760222c417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipywidgets) (8.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: backcall in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.11.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd49919-10d8-4891-be0a-0c4d6f454968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-text in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow-text) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.44.0)\n",
      "Requirement already satisfied: rich in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (7.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (2.15.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.20.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d374127-32ca-4f40-90d6-c1a4f0382723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55b6fe10-0be8-4353-8363-5e1e176597d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  \n",
    "#import tensorflow_datasets as tfds\n",
    "import tensorflow_text\n",
    "import keras_nlp\n",
    "import keras\n",
    "import time\n",
    "\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e2db8a-6ffc-4eae-b28d-41379aa0d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To speed up training and generation, we use preprocessor of length 128\n",
    "# instead of full length 1024.\n",
    "preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
    "    \"gpt2_base_en\",\n",
    "    sequence_length=128,\n",
    ")\n",
    "gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n",
    "    \"gpt2_base_en\", preprocessor=preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daa851d1-43fa-4346-bcb1-cf8b64c6c6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731494725.634857 50072335 service.cc:148] XLA service 0x60000273fb00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731494725.634897 50072335 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1731494725.637083 50072335 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPT-2 output:\n",
      "My trip to Yosemite was a bit of a blur because I was going through some of the most beautiful areas of the park and I wanted to take a look at what's out there. So I did.\n",
      "\n",
      "Here's a little bit about me:\n",
      "\n",
      "I'm a photographer, photographer's assistant, and photographer's assistant for The New York Times, which means that my photos aren't necessarily the best of what you can find on Google. So if you're looking for something more than just a little bit of fun, I recommend you check out this article.\n",
      "\n",
      "My favorite place to be in Yosemite is in the park, and I love to see how the landscape changes over time. The Yosemite Valley is a pretty big, wide, and beautiful place to be.\n",
      "\n",
      "The most beautiful thing about Yosemite Valley is the view of the valley. I love it when you see the mountains. I love it when you see the mountains. It's like a big world.\n",
      "\n",
      "\n",
      "TOTAL TIME ELAPSED: 19.74s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "output = gpt2_lm.generate(\"My trip to Yosemite was\", max_length=200)\n",
    "print(\"\\nGPT-2 output:\")\n",
    "print(output)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf0b7e07-4958-4a1d-b655-9c8ff6d99340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPT-2 output:\n",
      "That Italian restaurant is called 'The Italian Grill' because the owner, who was born in Italy, is Italian and has been here since he was a teenager. The owner's daughter, who is also Italian, is also Italian.\n",
      "\n",
      "But it is not just the restaurant owners and owners who have been affected by Italian restaurants, but the restaurant's staff.\n",
      "\n",
      "The restaurant's staff are not all Italian but some are Italian.\n",
      "\n",
      "They include a chef, who is not Italian, and a waitress who is Italian, according to the restaurant's Facebook page.\n",
      "\n",
      "The restaurant is not the only one that is affected by the Italian restaurants.\n",
      "\n",
      "According to the New York Post, a number of restaurants across the U.S. are also affected by Italian restaurants.\n",
      "\n",
      "The Post reports that the Italian Restaurant Association of Greater New York has been contacted to offer a list of restaurants that may be affected.\n",
      "\n",
      "\"It is very unfortunate that a restaurant that has been serving\n",
      "TOTAL TIME ELAPSED: 18.16s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "output = gpt2_lm.generate(\"That Italian restaurant is\", max_length=200)\n",
    "print(\"\\nGPT-2 output:\")\n",
    "print(output)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e9a140-3996-41a2-b053-aed3362fea0e",
   "metadata": {},
   "source": [
    "## GPT text generation from scratch with KerasHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34fbf1b5-65c1-41c7-b0a0-86de3dd07d9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-hub in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (0.17.0)\n",
      "Requirement already satisfied: absl-py in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras-hub) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras-hub) (2.0.2)\n",
      "Requirement already satisfied: packaging in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras-hub) (24.1)\n",
      "Requirement already satisfied: regex in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras-hub) (2024.11.6)\n",
      "Requirement already satisfied: rich in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras-hub) (13.9.4)\n",
      "Requirement already satisfied: kagglehub in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from keras-hub) (0.3.4)\n",
      "Requirement already satisfied: requests in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from kagglehub->keras-hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from kagglehub->keras-hub) (4.67.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from rich->keras-hub) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from rich->keras-hub) (2.15.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from rich->keras-hub) (4.11.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras-hub) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests->kagglehub->keras-hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests->kagglehub->keras-hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests->kagglehub->keras-hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages (from requests->kagglehub->keras-hub) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1836977-c44b-4ee5-88a3-a68b19dc751f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras_hub\n",
    "import keras\n",
    "import tensorflow.strings as tf_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12e73792-879b-49ca-aea3-850f7f305d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "BATCH_SIZE = 64\n",
    "MIN_STRING_LEN = 512  # Strings shorter than this will be discarded\n",
    "SEQ_LEN = 128  # Length of training sequences, in tokens\n",
    "\n",
    "# Model\n",
    "EMBED_DIM = 256\n",
    "FEED_FORWARD_DIM = 128\n",
    "NUM_HEADS = 3\n",
    "NUM_LAYERS = 2\n",
    "VOCAB_SIZE = 5000  # Limits parameters in model.\n",
    "\n",
    "# Training\n",
    "EPOCHS = 5\n",
    "\n",
    "# Inference\n",
    "NUM_TOKENS_TO_GENERATE = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e967c8e-89c6-49f9-98c0-303391252365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\n",
      "\u001b[1m282386239/282386239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/borja/Desktop/Portfolio/NLP/datasets/simplebooks.zip'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = keras.utils.get_file(\n",
    "    origin=\"https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\",\n",
    "    extract=True,\n",
    "    cache_dir= \"/Users/borja/Desktop/Portfolio/NLP\"\n",
    ")\n",
    "#dir = os.path.expanduser(\"/Users/borja/Desktop/Portfolio/NLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c748f070-0d16-4b7b-9a56-6741c5c806c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_ds = (\n",
    "    tf_data.TextLineDataset(dir + \"/datasets/simplebooks.zip/simplebooks/simplebooks-92-raw/train.txt\")\n",
    "    .filter(lambda x: tf_strings.length(x) > MIN_STRING_LEN)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .shuffle(buffer_size=256)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e72881bd-a2bd-4f91-ac43-88061149325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val_ds = (\n",
    "    tf_data.TextLineDataset(dir + \"/datasets/simplebooks.zip/simplebooks/simplebooks-92-raw/valid.txt\")\n",
    "    .filter(lambda x: tf_strings.length(x) > MIN_STRING_LEN)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "368195e3-56dc-4046-8080-a688f2f6cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train tokenizer vocabulary\n",
    "vocab = keras_hub.tokenizers.compute_word_piece_vocabulary(\n",
    "    raw_train_ds,\n",
    "    vocabulary_size=VOCAB_SIZE,\n",
    "    lowercase=True,\n",
    "    reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb44b9cd-6ada-4025-b02c-746c73c6905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras_hub.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=vocab,\n",
    "    sequence_length=SEQ_LEN,\n",
    "    lowercase=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b0f42a05-84e3-4aa7-941f-0c8d525864ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.data as tf_data\n",
    "\n",
    "# packer adds a start token\n",
    "start_packer = keras_hub.layers.StartEndPacker(\n",
    "    sequence_length=SEQ_LEN,\n",
    "    start_value=tokenizer.token_to_id(\"[BOS]\"),\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess(inputs):\n",
    "    outputs = tokenizer(inputs)\n",
    "    features = start_packer(outputs)\n",
    "    labels = outputs\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "# Tokenize and split into train and label sequences.\n",
    "train_ds = raw_train_ds.map(preprocess, num_parallel_calls=tf_data.AUTOTUNE).prefetch(\n",
    "    tf_data.AUTOTUNE\n",
    ")\n",
    "val_ds = raw_val_ds.map(preprocess, num_parallel_calls=tf_data.AUTOTUNE).prefetch(\n",
    "    tf_data.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c97dd034-da32-4046-8a63-fa5b65de8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(None,), dtype=\"int32\")\n",
    "# Embedding.\n",
    "embedding_layer = keras_hub.layers.TokenAndPositionEmbedding(\n",
    "    vocabulary_size=VOCAB_SIZE,\n",
    "    sequence_length=SEQ_LEN,\n",
    "    embedding_dim=EMBED_DIM,\n",
    "    mask_zero=True,\n",
    ")\n",
    "x = embedding_layer(inputs)\n",
    "# Transformer decoders.\n",
    "for _ in range(NUM_LAYERS):\n",
    "    decoder_layer = keras_hub.layers.TransformerDecoder(\n",
    "        num_heads=NUM_HEADS,\n",
    "        intermediate_dim=FEED_FORWARD_DIM,\n",
    "    )\n",
    "    x = decoder_layer(x)  # Giving one argument only skips cross-attention.\n",
    "# Output.\n",
    "outputs = keras.layers.Dense(VOCAB_SIZE)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "perplexity = keras_hub.metrics.Perplexity(from_logits=True, mask_token_id=0)\n",
    "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[perplexity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5fadf68b-7338-4744-bc93-dea98bdbce05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ token_and_position_embedding    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">329,085</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_decoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">329,085</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ token_and_position_embedding    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,312,768\u001b[0m │\n",
       "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m329,085\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_decoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m329,085\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)     │     \u001b[38;5;34m1,285,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,255,938</span> (12.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,255,938\u001b[0m (12.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,255,938</span> (12.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,255,938\u001b[0m (12.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2f4c79c-349d-4d08-8700-d2ee12a16df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'position_embedding' (of type PositionEmbedding) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/site-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2445/Unknown \u001b[1m2124s\u001b[0m 866ms/step - loss: 4.9946 - perplexity: 181.5923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/borja/anaconda3/envs/NLPKeras/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2445/2445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2125s\u001b[0m 866ms/step - loss: 4.9944 - perplexity: 181.5578 - val_loss: 4.2076 - val_perplexity: 67.2965\n",
      "Epoch 2/5\n",
      "\u001b[1m2445/2445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868ms/step - loss: 4.1799 - perplexity: 65.4335"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 17:50:09.836615: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2445/2445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2126s\u001b[0m 868ms/step - loss: 4.1799 - perplexity: 65.4321 - val_loss: 4.0977 - val_perplexity: 60.3031\n",
      "Epoch 3/5\n",
      "\u001b[1m2445/2445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2109s\u001b[0m 861ms/step - loss: 4.0389 - perplexity: 56.8078 - val_loss: 4.0228 - val_perplexity: 55.9280\n",
      "Epoch 4/5\n",
      "\u001b[1m2445/2445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2135s\u001b[0m 872ms/step - loss: 3.9625 - perplexity: 52.6210 - val_loss: 3.9748 - val_perplexity: 53.3349\n",
      "Epoch 5/5\n",
      "\u001b[1m2445/2445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2126s\u001b[0m 868ms/step - loss: 3.9173 - perplexity: 50.2951 - val_loss: 3.9641 - val_perplexity: 52.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x34e6acfa0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c9b4de76-0f7b-4326-adfb-889b7bb7c022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       "array([[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The \"packer\" layers adds the [BOS] token for us.\n",
    "prompt_tokens = start_packer(tokenizer([\"\"]))\n",
    "prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "78514f0e-2374-4cb3-ab79-de094c9cc56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next(prompt, cache, index):\n",
    "    logits = model(prompt)[:, index -1 , :]\n",
    "    # Ignore hidden states for now; only needed for contrastive search.\n",
    "    #cache = True\n",
    "    hidden_states = None\n",
    "    return logits, hidden_states, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "960e2e15-3830-4ca1-9d33-df8064ec27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fef37b-c43f-4e1b-9dca-eff62f618c24",
   "metadata": {},
   "source": [
    "### Greedy search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "563964de-419d-431f-9aa6-70e99b5948af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy search generated text: \n",
      "['[BOS] \" i have been thinking of the matter over , \" the captain said , \" but i have been a good deal of trouble , and i have been able to get a good deal of money , and i have been able to get a good deal of money , and i have been able to get a good deal of money , and i have been obliged to pay for a good deal of money , and i have been obliged to pay for a good price for a good price . i have been obliged to pay for a good price , and i have been obliged to pay for a good price for money , and i have been obliged to pay']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = keras_hub.samplers.GreedySampler()\n",
    "output_tokens = sampler(\n",
    "    next=next,\n",
    "    prompt=prompt_tokens,\n",
    "    index=1,  # Start sampling immediately after the [BOS] token.\n",
    ")\n",
    "txt = tokenizer.detokenize(output_tokens)\n",
    "print(f\"Greedy search generated text: \\n{txt}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03638e71-df34-4f9e-ad63-7d45b59fa968",
   "metadata": {},
   "source": [
    "### Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6bd81b2e-9e88-4ba4-8b35-6e7d0cfc4c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam search generated text: \n",
      "['[BOS] \" well , i don \\' t know , \" he said , \" but i don \\' t mean to say anything about it . i don \\' t mean to say anything about it , but i don \\' t know it . i don \\' t like it , but i don \\' t like it . i don \\' t like it , but i don \\' t like it . i don \\' t like it , but i don \\' t like it . i don \\' t like it . i don \\' t like it , but i don \\' t like it . i don \\' t like it . i don \\' t like it . i']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = keras_hub.samplers.BeamSampler(num_beams=10)\n",
    "output_tokens = sampler(\n",
    "    next=next,\n",
    "    prompt=prompt_tokens,\n",
    "    index=1,\n",
    ")\n",
    "txt = tokenizer.detokenize(output_tokens)\n",
    "print(f\"Beam search generated text: \\n{txt}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb853a-91f3-40da-8446-477999f1ea32",
   "metadata": {},
   "source": [
    "### Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c688044d-af4e-4e88-ac9f-3da6842877bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random search generated text: \n",
      "['[BOS] at the time there the party marched from sandy bayne hoofs that the indians in the forests and sordebigre returned from the valley , and his men upon his flank the cavalry pressed forward at amleay meeting at the callers . towards night they marched again a little down by the two of the bomy guards in river . several times he reached their ranks again . accidentally margaretville returned to their homes and lay down stones running around the hills laid bare and stretched themselves in tents . as slowly poles were the circles dragged to one , the retainer bugain and he']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = keras_hub.samplers.RandomSampler()\n",
    "output_tokens = sampler(\n",
    "    next=next,\n",
    "    prompt=prompt_tokens,\n",
    "    index=1,\n",
    ")\n",
    "txt = tokenizer.detokenize(output_tokens)\n",
    "print(f\"Random search generated text: \\n{txt}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733bfe3b-ed5b-46ad-826b-f94a2716f1e8",
   "metadata": {},
   "source": [
    "### Top-K search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7e544996-b1bf-4160-8db6-7ba0ffbd3852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-K search generated text: \n",
      "['[BOS] \" you must go with you , \" said hugh , putting his arm into one eye , \" he would have a good time . then you must have gone down into a little room , with you and your wife , and i am sure you are not a little so far away . if you would have done you , if you could find yourself at a moment , but you would have been more than a minute , and if you would only look at you to see the door open . you would see that you would not come up . it will be well enough , i will be glad to get you , \" he said , as he said']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = keras_hub.samplers.TopKSampler(k=10)\n",
    "output_tokens = sampler(\n",
    "    next=next,\n",
    "    prompt=prompt_tokens,\n",
    "    index=1,\n",
    ")\n",
    "txt = tokenizer.detokenize(output_tokens)\n",
    "print(f\"Top-K search generated text: \\n{txt}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c45ea-d8ae-4746-b8f1-c1eee5f2fdac",
   "metadata": {},
   "source": [
    "### Top-P search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c61d7ec7-93ad-4c1d-b9ef-c784ed4e3971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-P search generated text: \n",
      "['[BOS] \" i was a long time ago , \" he said , \" i suppose , indeed , \" the knight said , \" but you are not to say anything about it . now , as you say , it is well that it was not for me to be like all those of the damsels . i should say that there is nothing to be done . you have heard that this damsel is not the knight of the damsels , and so to speak to you , but i will say , that you have a damsel of honor and i shall be very glad to say that you have come to me , and so i will take the lady you']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = keras_hub.samplers.TopPSampler(p=0.5)\n",
    "output_tokens = sampler(\n",
    "    next=next,\n",
    "    prompt=prompt_tokens,\n",
    "    index=1,\n",
    ")\n",
    "txt = tokenizer.detokenize(output_tokens)\n",
    "print(f\"Top-P search generated text: \\n{txt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbada4ad-49df-40a6-a4ea-1a5c1a5d6270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
